name: SWHID Test Suite (Multi-Platform)

on:
  schedule:
    - cron: "17 2 * * *"  # Nightly run at 2:17 AM UTC
  workflow_dispatch:

jobs:
  check-changes:
    runs-on: ubuntu-24.04
    permissions:
      contents: read
      actions: read
    outputs:
      changes_detected: ${{ steps.check-changes.outputs.changes_detected }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.12
      
      - name: Install Software Heritage Python tools
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install swh.model swh.core || echo "Warning: swh Python tools not available"
        continue-on-error: true
      
      - name: Set up Ruby (for version checking)
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: '3.2'
          bundler-cache: false
        continue-on-error: true
      
      - name: Find previous workflow run
        id: find-previous-run
        uses: actions/github-script@v8
        continue-on-error: true
        with:
          script: |
            try {
              // context.workflow returns the workflow name, not the file path
              // We need to use the actual workflow file path
              const workflowFile = '.github/workflows/test-multi-platform.yml';
              
              // Try multiple ways to identify the workflow
              const workflowIdentifiers = [
                workflowFile,  // Full path to workflow file (most reliable)
                'test-multi-platform.yml',  // Just filename
                context.workflow,  // Workflow name (may not work)
              ];
              
              console.log(`Current workflow context: ${context.workflow}`);
              console.log(`Repository: ${context.repo.owner}/${context.repo.repo}`);
              console.log(`Workflow file: ${workflowFile}`);
              
              let workflowRuns = null;
              let lastError = null;
              
              // Try each workflow identifier
              for (const workflowId of workflowIdentifiers) {
                try {
                  console.log(`Trying workflow_id: ${workflowId}`);
                  workflowRuns = await github.rest.actions.listWorkflowRuns({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    workflow_id: workflowId,
                    status: 'success',
                    per_page: 2
                  });
                  
                  if (workflowRuns.data.workflow_runs && workflowRuns.data.workflow_runs.length > 0) {
                    console.log(`âœ“ Found ${workflowRuns.data.workflow_runs.length} workflow run(s) with identifier: ${workflowId}`);
                    break;
                  }
                } catch (err) {
                  console.log(`âœ— Failed with ${workflowId}: ${err.message}`);
                  lastError = err;
                  continue;
                }
              }
              
              if (!workflowRuns || !workflowRuns.data.workflow_runs || workflowRuns.data.workflow_runs.length < 2) {
                console.log('No previous successful run found (need at least 2 runs)');
                if (workflowRuns && workflowRuns.data.workflow_runs) {
                  console.log(`Found ${workflowRuns.data.workflow_runs.length} run(s), but need 2+ for comparison`);
                }
                core.setOutput('artifact_id', '');
                return;
              }
              
              const previousRun = workflowRuns.data.workflow_runs[1];
              console.log(`Found previous run: ${previousRun.id} (created: ${previousRun.created_at})`);
              
              const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                owner: context.repo.owner,
                repo: context.repo.repo,
                run_id: previousRun.id
              });
              
              console.log(`Found ${artifacts.data.artifacts.length} artifact(s) in previous run`);
              artifacts.data.artifacts.forEach(a => {
                console.log(`  - ${a.name} (${a.size_in_bytes} bytes, expires: ${a.expires_at})`);
              });
              
              const upstreamStateArtifact = artifacts.data.artifacts.find(a => a.name === 'upstream-state');
              
              if (!upstreamStateArtifact) {
                console.log('upstream-state artifact not found in previous run');
                core.setOutput('artifact_id', '');
                return;
              }
              
              console.log(`Found upstream-state artifact: ${upstreamStateArtifact.id}`);
              core.setOutput('artifact_id', upstreamStateArtifact.id.toString());
            } catch (error) {
              console.log(`Error finding previous run: ${error.message}`);
              console.log(`Error stack: ${error.stack}`);
              core.setOutput('artifact_id', '');
            }
      
      - name: Download previous run state (if available)
        if: steps.find-previous-run.outputs.artifact_id != ''
        shell: bash
        continue-on-error: true
        run: |
          mkdir -p previous-state
          ARTIFACT_ID="${{ steps.find-previous-run.outputs.artifact_id }}"
          
          curl -L -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/artifacts/${ARTIFACT_ID}/zip" \
            -o /tmp/upstream-state.zip
          
          if [ -f /tmp/upstream-state.zip ] && [ -s /tmp/upstream-state.zip ]; then
            echo "Artifact downloaded successfully, size: $(wc -c < /tmp/upstream-state.zip) bytes"
            unzip -l /tmp/upstream-state.zip || true
            unzip -q /tmp/upstream-state.zip -d /tmp/ 2>/dev/null || true
            
            # Debug: show what was extracted
            echo "Contents of /tmp after extraction:"
            find /tmp -name "*.txt" -o -name "current-state" -type d 2>/dev/null | head -20 || true
            
            # Artifact structure: GitHub Actions uploads from 'current-state/' directory
            # The zip may contain files directly or in a subdirectory
            # Try in order: direct files, nested structure, flat structure
            if find /tmp -maxdepth 1 -name "*.txt" | grep -q .; then
              echo "Found files directly in /tmp (flat zip structure)"
              cp /tmp/*.txt previous-state/ 2>/dev/null || true
            elif [ -d /tmp/upstream-state/current-state ]; then
              echo "Found nested structure: /tmp/upstream-state/current-state"
              cp -r /tmp/upstream-state/current-state/* previous-state/ 2>/dev/null || true
            elif [ -d /tmp/current-state ]; then
              echo "Found flat structure: /tmp/current-state"
              cp -r /tmp/current-state/* previous-state/ 2>/dev/null || true
            elif [ -d /tmp/upstream-state ]; then
              echo "Found upstream-state directory"
              # Check if files are directly in upstream-state or in a subdirectory
              if find /tmp/upstream-state -maxdepth 1 -name "*.txt" | grep -q .; then
                echo "Files directly in upstream-state"
                cp /tmp/upstream-state/*.txt previous-state/ 2>/dev/null || true
              else
                # Look for any .txt files in subdirectories
                find /tmp/upstream-state -name "*.txt" -exec cp {} previous-state/ \; 2>/dev/null || true
              fi
            else
              echo "Warning: Could not find expected directory structure, searching recursively"
              # Try to find any .txt files anywhere in /tmp (excluding hidden dirs)
              find /tmp -name "*.txt" -not -path "*/.*" -exec cp {} previous-state/ \; 2>/dev/null || true
            fi
            
            echo "Successfully downloaded previous state"
            echo "Files in previous-state:"
            ls -la previous-state/ || true
            echo "File count: $(find previous-state -name '*.txt' | wc -l)"
          else
            echo "Failed to download artifact or artifact is empty"
            mkdir -p previous-state
          fi
      
      - name: Check for upstream changes
        id: check-changes
        shell: bash
        run: |
          echo "## ðŸ” Checking for Upstream Changes" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          CHANGES_DETECTED=false
          
          # Get current state
          CURRENT_TEST_SUITE_SHA=$(git rev-parse HEAD)
          CURRENT_SWH_MODEL_VERSION=""
          CURRENT_SWH_CORE_VERSION=""
          CURRENT_SWHID_GEM_VERSION=""
          CURRENT_SWHID_RS_SHA=""
          
          # Check changes in swhid-rs repository
          echo "### swhid-rs Repository" >> $GITHUB_STEP_SUMMARY
          SWHID_RS_REPO="swhid/swhid-rs"
          SWHID_RS_REF="main"
          # Get latest commit SHA from GitHub API
          # Use SWHID_RS_TOKEN if available (for private repos or rate limits), fallback to GITHUB_TOKEN
          SWHID_RS_TOKEN="${{ secrets.SWHID_RS_TOKEN }}"
          if [ -z "$SWHID_RS_TOKEN" ] || [ "$SWHID_RS_TOKEN" = "" ]; then
            SWHID_RS_TOKEN="${{ secrets.GITHUB_TOKEN }}"
            echo "Using GITHUB_TOKEN for swhid-rs API" >> $GITHUB_STEP_SUMMARY
          else
            echo "Using SWHID_RS_TOKEN for swhid-rs API" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Try to fetch commit SHA with better error handling
          # Store response in temp file to handle both stdout and stderr
          TEMP_RESPONSE=$(mktemp)
          TEMP_ERROR=$(mktemp)
          
          HTTP_CODE=$(curl -s -w "%{http_code}" -o "$TEMP_RESPONSE" \
            -H "Authorization: Bearer ${SWHID_RS_TOKEN}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${SWHID_RS_REPO}/commits/${SWHID_RS_REF}" 2>"$TEMP_ERROR")
          
          if [ "$HTTP_CODE" = "200" ]; then
            # Try multiple parsing methods
            # Method 1: Direct grep for "sha" field
            CURRENT_SWHID_RS_SHA=$(grep -o '"sha":"[^"]*"' "$TEMP_RESPONSE" | head -1 | cut -d'"' -f4 || echo "")
            
            # Method 2: If that fails, try with jq if available
            if [ -z "$CURRENT_SWHID_RS_SHA" ] && command -v jq >/dev/null 2>&1; then
              CURRENT_SWHID_RS_SHA=$(jq -r '.sha' "$TEMP_RESPONSE" 2>/dev/null || echo "")
            fi
            
            # Method 3: Try extracting from any "sha" field in the JSON
            if [ -z "$CURRENT_SWHID_RS_SHA" ]; then
              CURRENT_SWHID_RS_SHA=$(grep -oE '"sha"\s*:\s*"[a-f0-9]{40}"' "$TEMP_RESPONSE" | head -1 | grep -oE '[a-f0-9]{40}' || echo "")
            fi
            
            if [ -z "$CURRENT_SWHID_RS_SHA" ]; then
              echo "âš ï¸ API returned 200 but could not parse SHA from response" >> $GITHUB_STEP_SUMMARY
              echo "Response preview (first 200 chars): $(head -c 200 "$TEMP_RESPONSE")" >> $GITHUB_STEP_SUMMARY
              # Check if response is valid JSON
              if command -v jq >/dev/null 2>&1; then
                if ! jq empty "$TEMP_RESPONSE" 2>/dev/null; then
                  echo "Response is not valid JSON" >> $GITHUB_STEP_SUMMARY
                fi
              fi
            fi
          else
            ERROR_MSG=$(cat "$TEMP_ERROR" 2>/dev/null || echo "Unknown error")
            echo "âš ï¸ API returned HTTP $HTTP_CODE" >> $GITHUB_STEP_SUMMARY
            if [ "$HTTP_CODE" = "401" ] || [ "$HTTP_CODE" = "403" ]; then
              echo "Authentication failed - token may be invalid or expired" >> $GITHUB_STEP_SUMMARY
            elif [ "$HTTP_CODE" = "404" ]; then
              echo "Repository or branch not found: ${SWHID_RS_REPO}#${SWHID_RS_REF}" >> $GITHUB_STEP_SUMMARY
            elif [ "$HTTP_CODE" = "000" ]; then
              echo "Network error or connection failed: $ERROR_MSG" >> $GITHUB_STEP_SUMMARY
            else
              echo "Error: $ERROR_MSG" >> $GITHUB_STEP_SUMMARY
            fi
            CURRENT_SWHID_RS_SHA=""
          fi
          
          rm -f "$TEMP_RESPONSE" "$TEMP_ERROR"
          
          if [ -n "$CURRENT_SWHID_RS_SHA" ]; then
            if [ -f previous-state/swhid-rs-sha.txt ]; then
              PREVIOUS_SHA=$(cat previous-state/swhid-rs-sha.txt)
              if [ "$CURRENT_SWHID_RS_SHA" != "$PREVIOUS_SHA" ]; then
                echo "âš ï¸ **Changes detected in swhid-rs repository**" >> $GITHUB_STEP_SUMMARY
                echo "Previous: \`${PREVIOUS_SHA:0:7}\` â†’ Current: \`${CURRENT_SWHID_RS_SHA:0:7}\`" >> $GITHUB_STEP_SUMMARY
                echo "Repository: https://github.com/${SWHID_RS_REPO}/compare/${PREVIOUS_SHA:0:7}...${CURRENT_SWHID_RS_SHA:0:7}" >> $GITHUB_STEP_SUMMARY
                CHANGES_DETECTED=true
              else
                echo "âœ… No changes in swhid-rs repository" >> $GITHUB_STEP_SUMMARY
                echo "Current commit: \`${CURRENT_SWHID_RS_SHA:0:7}\`" >> $GITHUB_STEP_SUMMARY
              fi
            else
              echo "â„¹ï¸ No previous state found (first run or artifact expired)" >> $GITHUB_STEP_SUMMARY
              echo "Current commit: \`${CURRENT_SWHID_RS_SHA:0:7}\`" >> $GITHUB_STEP_SUMMARY
              CHANGES_DETECTED=true
            fi
          else
            echo "â„¹ï¸ Could not fetch swhid-rs commit SHA (API may be unavailable)" >> $GITHUB_STEP_SUMMARY
            # If we can't check, assume changes to be safe
            CHANGES_DETECTED=true
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check changes in test-suite repository
          echo "### Test Suite Repository" >> $GITHUB_STEP_SUMMARY
          if [ -f previous-state/test-suite-sha.txt ]; then
            PREVIOUS_SHA=$(cat previous-state/test-suite-sha.txt)
            if [ "$CURRENT_TEST_SUITE_SHA" != "$PREVIOUS_SHA" ]; then
              echo "âš ï¸ **Changes detected in test-suite repository**" >> $GITHUB_STEP_SUMMARY
              echo "Previous: \`${PREVIOUS_SHA:0:7}\` â†’ Current: \`${CURRENT_TEST_SUITE_SHA:0:7}\`" >> $GITHUB_STEP_SUMMARY
              echo "Recent commits:" >> $GITHUB_STEP_SUMMARY
              git log --oneline ${PREVIOUS_SHA}..${CURRENT_TEST_SUITE_SHA} | head -5 >> $GITHUB_STEP_SUMMARY || true
              CHANGES_DETECTED=true
            else
              echo "âœ… No changes in test-suite repository" >> $GITHUB_STEP_SUMMARY
              echo "Current commit: \`${CURRENT_TEST_SUITE_SHA:0:7}\`" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "â„¹ï¸ No previous state found (first run or artifact expired)" >> $GITHUB_STEP_SUMMARY
            echo "Current commit: \`${CURRENT_TEST_SUITE_SHA:0:7}\`" >> $GITHUB_STEP_SUMMARY
            CHANGES_DETECTED=true
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check for updates in swh Python packages
          echo "### Software Heritage Python Packages" >> $GITHUB_STEP_SUMMARY
          PACKAGES="swh.model swh.core"
          for package in $PACKAGES; do
            INSTALLED_VERSION=$(pip show $package 2>/dev/null | grep "^Version:" | awk '{print $2}' || echo "not installed")
            if [ "$INSTALLED_VERSION" != "not installed" ]; then
              if [ "$package" = "swh.model" ]; then
                CURRENT_SWH_MODEL_VERSION="$INSTALLED_VERSION"
              elif [ "$package" = "swh.core" ]; then
                CURRENT_SWH_CORE_VERSION="$INSTALLED_VERSION"
              fi
              
              if [ -f previous-state/${package}-version.txt ]; then
                PREVIOUS_VERSION=$(cat previous-state/${package}-version.txt)
                if [ "$INSTALLED_VERSION" != "$PREVIOUS_VERSION" ]; then
                  echo "âš ï¸ **$package**: Previous: \`$PREVIOUS_VERSION\` â†’ Current: \`$INSTALLED_VERSION\`" >> $GITHUB_STEP_SUMMARY
                  CHANGES_DETECTED=true
                else
                  echo "âœ… **$package**: \`$INSTALLED_VERSION\` (unchanged)" >> $GITHUB_STEP_SUMMARY
                fi
              else
                LATEST_VERSION=$(pip index versions $package 2>/dev/null | grep "LATEST:" | awk '{print $2}' || echo "")
                if [ -n "$LATEST_VERSION" ] && [ "$INSTALLED_VERSION" != "$LATEST_VERSION" ]; then
                  echo "âš ï¸ **$package**: Installed: \`$INSTALLED_VERSION\`, Latest: \`$LATEST_VERSION\`" >> $GITHUB_STEP_SUMMARY
                  CHANGES_DETECTED=true
                else
                  echo "âœ… **$package**: \`$INSTALLED_VERSION\` (latest)" >> $GITHUB_STEP_SUMMARY
                fi
              fi
            else
              echo "â„¹ï¸ **$package**: Not installed" >> $GITHUB_STEP_SUMMARY
            fi
          done
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check for updates in Ruby gem
          echo "### Ruby Gem (swhid)" >> $GITHUB_STEP_SUMMARY
          if command -v gem >/dev/null 2>&1; then
            # Get latest version from RubyGems without installing
            # gem search -r swhid outputs: "swhid (X.Y.Z)" or "swhid (X.Y.Z, X.Y.Z-1, ...)"
            GEM_SEARCH_OUTPUT=$(gem search -r -e swhid 2>/dev/null | grep -E "^swhid\s" | head -1 || echo "")
            if [ -n "$GEM_SEARCH_OUTPUT" ]; then
              # Extract version: "swhid (1.2.3)" -> "1.2.3"
              LATEST_GEM_VERSION=$(echo "$GEM_SEARCH_OUTPUT" | sed -E 's/^swhid\s+\(([^,)]+).*\)$/\1/' | xargs)
              if [ -n "$LATEST_GEM_VERSION" ]; then
                CURRENT_SWHID_GEM_VERSION="$LATEST_GEM_VERSION"
                if [ -f previous-state/swhid-gem-version.txt ]; then
                  PREVIOUS_VERSION=$(cat previous-state/swhid-gem-version.txt)
                  if [ "$LATEST_GEM_VERSION" != "$PREVIOUS_VERSION" ]; then
                    echo "âš ï¸ **swhid gem**: Previous: \`$PREVIOUS_VERSION\` â†’ Current: \`$LATEST_GEM_VERSION\`" >> $GITHUB_STEP_SUMMARY
                    CHANGES_DETECTED=true
                  else
                    echo "âœ… **swhid gem**: \`$LATEST_GEM_VERSION\` (unchanged)" >> $GITHUB_STEP_SUMMARY
                  fi
                else
                  echo "â„¹ï¸ **swhid gem**: \`$LATEST_GEM_VERSION\` (first check)" >> $GITHUB_STEP_SUMMARY
                  CHANGES_DETECTED=true
                fi
              else
                echo "â„¹ï¸ **swhid gem**: Could not parse version from: $GEM_SEARCH_OUTPUT" >> $GITHUB_STEP_SUMMARY
              fi
            else
              echo "â„¹ï¸ **swhid gem**: Could not find gem in RubyGems" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "â„¹ï¸ **swhid gem**: Ruby/gem not available for version checking" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Summary
          if [ "$CHANGES_DETECTED" = "true" ]; then
            echo "### ðŸ“Š Summary" >> $GITHUB_STEP_SUMMARY
            echo "âš ï¸ **Changes detected upstream** - Test suite will run" >> $GITHUB_STEP_SUMMARY
            echo "changes_detected=true" >> $GITHUB_OUTPUT
          else
            echo "### ðŸ“Š Summary" >> $GITHUB_STEP_SUMMARY
            echo "âœ… **No upstream changes detected** - Skipping test suite to save resources" >> $GITHUB_STEP_SUMMARY
            echo "changes_detected=false" >> $GITHUB_OUTPUT
          fi
          
          # Save current state for next run
          mkdir -p current-state
          echo "$CURRENT_TEST_SUITE_SHA" > current-state/test-suite-sha.txt
          if [ -n "$CURRENT_SWHID_RS_SHA" ]; then
            echo "$CURRENT_SWHID_RS_SHA" > current-state/swhid-rs-sha.txt
          fi
          if [ -n "$CURRENT_SWH_MODEL_VERSION" ]; then
            echo "$CURRENT_SWH_MODEL_VERSION" > current-state/swh.model-version.txt
          fi
          if [ -n "$CURRENT_SWH_CORE_VERSION" ]; then
            echo "$CURRENT_SWH_CORE_VERSION" > current-state/swh.core-version.txt
          fi
          if [ -n "$CURRENT_SWHID_GEM_VERSION" ]; then
            echo "$CURRENT_SWHID_GEM_VERSION" > current-state/swhid-gem-version.txt
          fi
        continue-on-error: true
      
      - name: Upload current state for next run
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: upstream-state
          path: current-state
          retention-days: 90
        continue-on-error: true

  test:
    needs: check-changes
    if: needs.check-changes.outputs.changes_detected == 'true'
    name: Test (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    permissions:
      contents: read

    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]

    env:
      SWHID_RS_PROFILE: release
      SWHID_RS_FEATURES: git
      RUBY_VERSION: "3.2"
      PYTHON_VERSION: "3.12"

    steps:
      - name: Checkout test-suite
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # CRITICAL: Configure Git to preserve hash-sensitive attributes
      - name: Configure Git for SWHID testing
        shell: bash
        run: |
          git config --global core.autocrlf false
          git config --global core.filemode true
          git config --global core.precomposeunicode false
          git config --global core.quotepath false

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install system dependencies (Linux)
        if: runner.os == 'Linux'
        shell: bash
        run: |
          sudo apt-get update
          sudo apt-get install -y libssl-dev pkg-config ruby-dev build-essential libgit2-dev

      - name: Install system dependencies (macOS)
        if: runner.os == 'macOS'
        shell: bash
        run: |
          brew install libgit2 pkg-config openssl 2>&1 | grep -vE "(Warning:.*is already installed|To reinstall)" || true

      - name: Install system dependencies (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          # On Windows, libgit2 is optional - pygit2 can work without it in some cases
          # Try to install via vcpkg, but don't fail if it doesn't work
          if (Get-Command choco -ErrorAction SilentlyContinue) {
            choco install -y vcpkg 2>&1 | Out-Null
            if (Get-Command vcpkg -ErrorAction SilentlyContinue) {
              vcpkg install libgit2:x64-windows 2>&1 | Out-Null
            }
          }
        continue-on-error: true

      - name: Install Python dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install .[dev]

      - name: Install Software Heritage Python tools (optional)
        shell: bash
        run: |
          if [ "$RUNNER_OS" == "Windows" ]; then
            # swh.core has test data files with colons in names, which Windows doesn't support
            # swh.model is sufficient for the python implementation
            python -m pip install swh.model || echo "Warning: swh.model not available"
          else
            python -m pip install swh.model swh.core || echo "Warning: swh Python tools not available"
          fi
        continue-on-error: true

      - name: Set up Ruby
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: ${{ env.RUBY_VERSION }}
          bundler-cache: false
        continue-on-error: true

      # --------------------------------------------------------------------
      # Ruby gem caching: use a deterministic GEM_HOME we control
      # --------------------------------------------------------------------
      - name: Configure GEM_HOME
        shell: bash
        run: |
          set -euo pipefail
          echo "GEM_HOME=${{ runner.temp }}/gem-home" >> "$GITHUB_ENV"
          echo "GEM_PATH=${{ runner.temp }}/gem-home" >> "$GITHUB_ENV"
          echo "${{ runner.temp }}/gem-home/bin" >> "$GITHUB_PATH"

      - name: Cache GEM_HOME
        uses: actions/cache@v4
        with:
          path: ${{ runner.temp }}/gem-home
          # If there is a Gemfile.lock, incorporate it; otherwise keep a stable key
          key: gemhome-${{ runner.os }}-ruby-${{ env.RUBY_VERSION }}-${{ hashFiles('**/Gemfile.lock') }}
          restore-keys: |
            gemhome-${{ runner.os }}-ruby-${{ env.RUBY_VERSION }}-
            gemhome-${{ runner.os }}-

      - name: Determine CPU cores
        id: cpu-cores
        shell: bash
        run: |
          if command -v nproc >/dev/null 2>&1; then
            echo "cores=$(nproc)" >> "$GITHUB_OUTPUT"
          elif [ "$RUNNER_OS" == "macOS" ]; then
            echo "cores=$(sysctl -n hw.ncpu)" >> "$GITHUB_OUTPUT"
          else
            # Fallback for Windows or other platforms
            echo "cores=4" >> "$GITHUB_OUTPUT"
          fi

      - name: Install swhid gem
        shell: bash
        run: |
          set -euo pipefail
          export MAKE="make -j${{ steps.cpu-cores.outputs.cores }}"
          if ! ruby -e "require 'swhid'" >/dev/null 2>&1; then
            gem install swhid --no-document || echo "Ruby implementation skip"
          fi

      - name: Verify Ruby gem installation
        shell: bash
        run: |
          set -euo pipefail
          echo "=== Ruby Gem Installation Verification ==="
          echo "GEM_HOME: $GEM_HOME"
          echo "GEM_PATH: $GEM_PATH"
          echo ""
          echo "=== Checking GEM_HOME/bin directory ==="
          if [ -n "$GEM_HOME" ]; then
            GEM_BIN_DIR="$GEM_HOME/bin"
            echo "GEM_HOME/bin: $GEM_BIN_DIR"
            if [ -d "$GEM_BIN_DIR" ]; then
              echo "âœ… Directory exists"
              echo "Files in GEM_HOME/bin:"
              ls -la "$GEM_BIN_DIR" || echo "Could not list directory"
              echo ""
              echo "=== Checking for swhid executables ==="
              for ext in "" ".bat" ".cmd" ".exe"; do
                SWHID_FILE="$GEM_BIN_DIR/swhid$ext"
                if [ -f "$SWHID_FILE" ]; then
                  echo "âœ… Found: $SWHID_FILE"
                  if [ "$RUNNER_OS" != "Windows" ]; then
                    if [ -x "$SWHID_FILE" ]; then
                      echo "   Executable: yes"
                    else
                      echo "   Executable: no"
                    fi
                  fi
                else
                  echo "âŒ Not found: $SWHID_FILE"
                fi
              done
            else
              echo "âŒ Directory does not exist: $GEM_BIN_DIR"
            fi
          else
            echo "âš ï¸ GEM_HOME is not set"
          fi
          echo ""
          echo "=== Checking PATH ==="
          if command -v swhid >/dev/null 2>&1; then
            echo "âœ… swhid found in PATH: $(which swhid)"
          else
            echo "âŒ swhid not found in PATH"
          fi
          if [ "$RUNNER_OS" == "Windows" ]; then
            if command -v swhid.bat >/dev/null 2>&1; then
              echo "âœ… swhid.bat found in PATH: $(which swhid.bat)"
            else
              echo "âŒ swhid.bat not found in PATH"
            fi
          fi
          echo ""
          echo "=== Testing Ruby require ==="
          if ruby -e "require 'swhid'" 2>&1; then
            echo "âœ… Ruby can require 'swhid'"
          else
            echo "âŒ Ruby cannot require 'swhid'"
          fi

      # Rust Build & Implementation Flags
      - name: Build swhid-rs with cache
        uses: ./.github/actions/build-swhid-rs
        with:
          rust: stable
          profile: ${{ env.SWHID_RS_PROFILE }}
          features: ${{ env.SWHID_RS_FEATURES }}
          repository: swhid/swhid-rs
          ref: main
          token: ${{ secrets.SWHID_RS_TOKEN }}

      - name: Add swhid-rs binary to PATH and export availability (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          set -euo pipefail
          TARGET_BIN="${CARGO_TARGET_DIR:-${{ runner.temp }}/cargo-target-swhid-rs}/release"
          BINARY_NAME="swhid"
          if [ -f "$TARGET_BIN/$BINARY_NAME" ]; then
            chmod +x "$TARGET_BIN/$BINARY_NAME"
            echo "$TARGET_BIN" >> "$GITHUB_PATH"
            # CRITICAL: Tell the harness swhid-rs is ready
            echo "swhid_rs_available=true" >> "$GITHUB_ENV"
            echo "SWHID_RS_PATH=$TARGET_BIN" >> "$GITHUB_ENV"
          else
            echo "WARNING: swhid binary not found at $TARGET_BIN/$BINARY_NAME"
            echo "swhid_rs_available=false" >> "$GITHUB_ENV"
          fi

      - name: Add swhid-rs binary to PATH and export availability (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $CARGO_TARGET_DIR = if ($env:CARGO_TARGET_DIR) { $env:CARGO_TARGET_DIR } else { "$env:RUNNER_TEMP\cargo-target-swhid-rs" }
          $TARGET_BIN = "$CARGO_TARGET_DIR\release"
          $BINARY_NAME = "swhid.exe"
          if (Test-Path "$TARGET_BIN\$BINARY_NAME") {
            "$TARGET_BIN" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
            # CRITICAL: Tell the harness swhid-rs is ready
            "swhid_rs_available=true" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
            "SWHID_RS_PATH=$TARGET_BIN" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
          } else {
            Write-Host "WARNING: swhid binary not found at $TARGET_BIN\$BINARY_NAME"
            "swhid_rs_available=false" | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
          }

      - name: Fix binary permissions after cache restore (Unix)
        if: runner.os != 'Windows'
        shell: bash
        run: |
          TARGET_BIN="${CARGO_TARGET_DIR:-${{ runner.temp }}/cargo-target-swhid-rs}/release"
          if [ -f "$TARGET_BIN/swhid" ]; then
            chmod +x "$TARGET_BIN/swhid"
            echo "âœ… Fixed binary permissions"
          fi

      - name: Verify swhid in PATH
        shell: bash
        run: |
          if [ "$RUNNER_OS" == "Windows" ]; then
            BINARY_NAME="swhid.exe"
          else
            BINARY_NAME="swhid"
          fi
          if command -v "$BINARY_NAME" >/dev/null 2>&1; then
            echo "âœ… swhid found: $(which $BINARY_NAME || where.exe $BINARY_NAME 2>/dev/null || echo 'found')"
            if "$BINARY_NAME" --help >/dev/null 2>&1; then
              echo "âœ… swhid is executable and responds to --help"
            else
              echo "âš ï¸ swhid found but does not respond to --help"
            fi
          else
            echo "âš ï¸ swhid not in PATH"
          fi

      - name: Run harness unit tests
        shell: bash
        run: |
          pytest tests/unit/ tests/integration/ -v --tb=short
      
      - name: Run full test suite
        shell: bash
        run: |
          swhid-harness --output-format canonical --dashboard-output results.json || true

      - name: Generate HTML results table
        if: always()
        shell: bash
        run: |
          if [ -f results.json ]; then
            python scripts/view_results.py results.json --output results.html || echo "Warning: Could not generate HTML table"
            if [ -f results.html ]; then
              echo "âœ… HTML results table generated: results.html" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "âš ï¸ No results.json file found, skipping HTML generation" >> $GITHUB_STEP_SUMMARY
          fi
        continue-on-error: true
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ matrix.os }}-py${{ env.PYTHON_VERSION }}
          path: |
            results.json
            results.html
          retention-days: 30
      
      - name: Generate test summary
        if: always()
        shell: bash
        run: |
          echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f results.json ]; then
            # Generate statistics
            python3 -c "import json; fp=open('results.json'); d=json.load(fp); fp.close(); a=d.get('aggregates',{}); b=a.get('by_implementation',{}); p=sum(s.get('passed',0) for s in b.values()); fa=sum(s.get('failed',0) for s in b.values()); sk=sum(s.get('skipped',0) for s in b.values()); t=p+fa+sk; r=(p/t*100) if t>0 else 0; print(f'| Metric | Value |'); print(f'|--------|-------|'); print(f'| Total Tests | {t} |'); print(f'| Passed | {p} |'); print(f'| Failed | {fa} |'); print(f'| Skipped | {sk} |'); print(f'| Success Rate | {r:.1f}% |') if b else print('| Note | Results format not recognized |')" >> $GITHUB_STEP_SUMMARY 2>&1 || echo "| Note | Error parsing results |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            # Add link to HTML results if available
            if [ -f results.html ]; then
              echo "### ðŸ“Š Detailed Results" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "ðŸ“¥ Download the [HTML results table](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) from the artifacts." >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "The HTML table provides a color-coded view of all test results across all implementations." >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "| Note | No results file (harness tests may have been skipped) |" >> $GITHUB_STEP_SUMMARY
          fi

  publish-dashboard:
    needs: [check-changes, test]
    if: github.ref == 'refs/heads/main' && needs.check-changes.outputs.changes_detected == 'true'
    runs-on: ubuntu-24.04
    permissions:
      contents: read
      pages: write
      id-token: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.12
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]
      
      - name: Merge results
        shell: bash
        run: |
          # Create a simple HTML summary if merge_results.py doesn't exist
          if [ -f tools/merge_results.py ]; then
            python tools/merge_results.py artifacts/**/results.json --site site
          else
            mkdir -p site
            echo "<html><body><h1>Test Results</h1><p>Results are available in the artifacts.</p></body></html>" > site/index.html
          fi
      
      - name: Generate dashboard
        shell: bash
        run: |
          python -m tools.dashboard \
            --site site \
            --data site/data \
            --artifacts artifacts
      
      - name: Check if Pages is enabled
        id: pages-check
        uses: actions/github-script@v8
        continue-on-error: true
        with:
          script: |
            try {
              // Check if pages API is available
              if (!github.rest || !github.rest.pages) {
                console.log('âš  Pages API not available in this context');
                console.log('âš  Attempting to proceed with Pages deployment anyway');
                console.log('âš  If deployment fails, ensure Pages is enabled in repository settings');
                core.setOutput('enabled', 'true'); // Try anyway
                return;
              }
              
              const pages = await github.rest.pages.get({ 
                owner: context.repo.owner, 
                repo: context.repo.repo 
              });
              
              console.log('Pages status:', JSON.stringify(pages.data, null, 2));
              
              // Check if Pages is configured for GitHub Actions
              if (pages.data && pages.data.source) {
                if (pages.data.source.type === 'workflow') {
                  console.log('âœ“ Pages is configured for GitHub Actions');
                  core.setOutput('enabled', 'true');
                } else if (pages.data.source.type === 'branch') {
                  console.log('âš  Pages is configured for branch deployment, not GitHub Actions');
                  console.log('âš  Please change Pages source to "GitHub Actions" in repository settings');
                  console.log('âš  Please change Pages source to "GitHub Actions" in repository settings');
                  core.setOutput('enabled', 'false');
                } else {
                  console.log('âš  Pages source type unknown:', pages.data.source.type);
                  console.log('âš  Attempting to proceed anyway');
                  core.setOutput('enabled', 'true'); // Try anyway
                }
              } else {
                console.log('âš  Pages data structure unexpected, attempting to proceed');
                core.setOutput('enabled', 'true'); // Try anyway
              }
            } catch (error) {
              console.log('âš  Pages API call failed, but attempting to proceed');
              console.log('Error:', error.message);
              console.log('');
              console.log('Note: If Pages deployment fails, ensure:');
              console.log('1. Pages is enabled in Settings â†’ Pages');
              console.log('2. Pages source is set to "GitHub Actions"');
              console.log('3. Ensure Pages is enabled and configured for GitHub Actions');
              // Try to proceed anyway - let configure-pages handle the actual check
              core.setOutput('enabled', 'true');
            }
      
      - name: Configure Pages
        if: steps.pages-check.outputs.enabled == 'true'
        uses: actions/configure-pages@v5
        continue-on-error: true
      
      - name: Verify site structure
        if: steps.pages-check.outputs.enabled == 'true'
        shell: bash
        run: |
          echo "Verifying site structure..."
          if [ ! -f site/index.html ]; then
            echo "ERROR: site/index.html not found!"
            echo "Site contents:"
            ls -la site/ || true
            find site/ -type f | head -20
            exit 1
          fi
          echo "âœ“ site/index.html exists"
          if [ -d site/data ]; then
            echo "âœ“ site/data/ directory exists"
            ls -la site/data/ || true
          fi
          if [ -d site/assets ]; then
            echo "âœ“ site/assets/ directory exists"
          fi
      
      - name: Upload Pages artifact
        if: steps.pages-check.outputs.enabled == 'true'
        uses: actions/upload-pages-artifact@v3
        with:
          path: site
        continue-on-error: true
      
      - name: Deploy to GitHub Pages
        if: steps.pages-check.outputs.enabled == 'true'
        uses: actions/deploy-pages@v4
        continue-on-error: true

  performance-baseline:
    needs: test
    runs-on: ubuntu-24.04
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
      
      - name: Update performance baselines
        run: |
          echo "Performance baseline update would go here"
          # This would update baseline performance files
          # and detect regressions
