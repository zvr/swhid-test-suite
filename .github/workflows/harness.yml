name: SWHID Testing Harness

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: "17 2 * * *"  # Nightly deep run at 2:17 AM UTC

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-24.04, macos-14, windows-2022]
        python-version: [3.10, 3.12]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for commit info
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev] psutil
      
      - name: Run harness unit tests
        run: |
          pytest tests/unit/ tests/integration/ -v --tb=short
      
      - name: Run harness with built-in implementations only
        if: github.event_name != 'schedule'
        run: |
          # Test harness with implementations that are guaranteed to be available
          # (git and pygit2 use Python packages, no external tools needed)
          swhid-harness --impl git,pygit2 --category content --output-format canonical --dashboard-output results.json || true
          echo "Harness test with built-in implementations completed"
      
      - name: Run full test suite (if implementations available)
        if: github.event_name == 'schedule'
        run: |
          # Scheduled runs can try all implementations, but gracefully handle missing ones
          swhid-harness --category content,directory --output-format canonical --dashboard-output results.json || true
          echo "Full test suite completed (some implementations may be skipped)"
      
      - name: Upload test results
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ matrix.os }}-py${{ matrix.python-version }}
          path: results.json
          retention-days: 30
      
      - name: Generate test summary
        run: |
          echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          if [ -f results.json ]; then
            python -c "
            import json
            try:
                with open('results.json', 'r') as f:
                    data = json.load(f)
                # Handle different result formats
                if 'aggregates' in data:
                    agg = data['aggregates']
                    if 'by_implementation' in agg:
                        total_passed = sum(s.get('passed', 0) for s in agg['by_implementation'].values())
                        total_failed = sum(s.get('failed', 0) for s in agg['by_implementation'].values())
                        total_skipped = sum(s.get('skipped', 0) for s in agg['by_implementation'].values())
                        total = total_passed + total_failed + total_skipped
                        rate = (total_passed / total * 100) if total > 0 else 0
                        print(f'| Total Tests | {total} |')
                        print(f'| Passed | {total_passed} |')
                        print(f'| Failed | {total_failed} |')
                        print(f'| Skipped | {total_skipped} |')
                        print(f'| Success Rate | {rate:.1f}% |')
                else:
                    print('| Note | Results format not recognized |')
            except Exception as e:
                print(f'| Error | {str(e)} |')
            " >> $GITHUB_STEP_SUMMARY
          else
            echo "| Note | No results file (harness tests may have been skipped) |" >> $GITHUB_STEP_SUMMARY
          fi

  publish-dashboard:
    needs: test
    if: github.ref == 'refs/heads/main' && github.event_name != 'schedule'
    runs-on: ubuntu-24.04
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.12
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]
      
      - name: Merge results
        run: |
          python tools/merge_results.py artifacts/**/results.json --site site
      
      - name: Configure Pages
        uses: actions/configure-pages@v5
      
      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: site
      
      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4

  performance-baseline:
    needs: test
    if: github.event_name == 'schedule'
    runs-on: ubuntu-24.04
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
      
      - name: Update performance baselines
        run: |
          echo "Performance baseline update would go here"
          # This would update baseline performance files
          # and detect regressions
